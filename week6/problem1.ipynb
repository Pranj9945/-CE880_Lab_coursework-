{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pranj9945/-CE880_Lab_coursework-/blob/main/week6/problem1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQXjxTc9PsJU"
      },
      "source": [
        "Before you turn this problem in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n",
        "\n",
        "Make sure you fill in any place that says `YOUR CODE HERE` or \"YOUR ANSWER HERE\", as well as your name and collaborators below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RAuj6FQsPsJW"
      },
      "outputs": [],
      "source": [
        "NAME = \"Pranjal Patil\"\n",
        "COLLABORATORS = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlFpsq6TPsJW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dX1oY3jnPsJX"
      },
      "source": [
        "---\n",
        "# Welcome to CE880\n",
        "### This is your week-6 : Problem notebook\n",
        "\n",
        "For this problem set, we'll be using the Jupyter notebook and please upload this notebook to [Google Colab](https://colab.research.google.com/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bszBz8IuPsJX"
      },
      "source": [
        "---\n",
        "## Question 1:\n",
        "\n",
        "Write a Python function to calculate the `false negative rate`, you need the `true labels` as well. The `false negative rate` is the proportion of `actual positive cases` that were incorrectly classified as `negative`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "0303f241ebccf763a33d1398b2539117",
          "grade": false,
          "grade_id": "my_ttest_ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "_JlogHLrPsJX"
      },
      "outputs": [],
      "source": [
        "def calculate_false_negative_rate(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the false negative rate given the true labels and predicted labels.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (numpy.ndarray or list): True labels.\n",
        "    - y_pred (numpy.ndarray or list): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - false_negative_rate (float): False negative rate.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    TP = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "      if y_true[i]==y_pred[i]==1:\n",
        "        TP += 1\n",
        "      if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
        "        FN += 1\n",
        "    FNR = FN/(FN+TP)\n",
        "    return FNR\n",
        "\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "fc57c0e15c295507ebef212934e478f4",
          "grade": true,
          "grade_id": "my_ttest_test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "qw4gzzdBPsJX"
      },
      "outputs": [],
      "source": [
        "# Check you solution by running this cell\n",
        "# Case 1\n",
        "y_true = [1, 0, 1, 1, 0, 0, 1, 0, 1]\n",
        "y_pred = [1, 0, 0, 1, 0, 1, 1, 0, 1]\n",
        "assert calculate_false_negative_rate(y_true, y_pred) == 0.2\n",
        "\n",
        "# Case 2\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 1]\n",
        "y_pred = [1, 1, 0, 1, 0, 0, 1, 1]\n",
        "assert calculate_false_negative_rate(y_true, y_pred) == 0.4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4WCOmlLQPsJX"
      },
      "source": [
        "---\n",
        "## Question 2:\n",
        "\n",
        "Write Python code to calculate the `F1-score`, you need the `true labels` as well as the `predicted labels`. The `F1-score` is a measure of a model's accuracy that considers both the `precision` and `recall` of the model.\n",
        "\n",
        "<img src=\"https://lh6.googleusercontent.com/JJuhZfvr8tq3asFRvSJwb1CwqMLKCfZGpjy6Cng35RSvq-5eEa9I9TPUjs1M6jgTSP5H-EiXrr8URnoiRICHWPGDE-fwMKmZNwVDBARhO4LcUgpO4Nj_bfLLNCshBc3vrYgqUO2Nj-THYwkmbr1J9fE\" alt=\"drawing\" style=\"width:400px;\"/>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "115516fdad289a9e6cdf3e2cb8c3980b",
          "grade": false,
          "grade_id": "my_pairedttest_ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "94oEA-9VPsJX"
      },
      "outputs": [],
      "source": [
        "def calculate_f1_score(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the F1-score given the true labels and predicted labels.\n",
        "\n",
        "    Parameters:\n",
        "    - y_true (numpy.ndarray or list): True labels.\n",
        "    - y_pred (numpy.ndarray or list): Predicted labels.\n",
        "\n",
        "    Returns:\n",
        "    - f1_score (float): F1-score.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    TN = 0\n",
        "    FN = 0\n",
        "\n",
        "    for i in range(len(y_pred)):\n",
        "      if y_true[i]==y_pred[i]==1:\n",
        "        TP += 1\n",
        "      if y_pred[i]==1 and y_true[i]!=y_pred[i]:\n",
        "        FP += 1\n",
        "      if y_true[i]==y_pred[i]==0:\n",
        "        TN += 1\n",
        "      if y_pred[i]==0 and y_true[i]!=y_pred[i]:\n",
        "        FN += 1\n",
        "    Recall = TP/(TP+FN)\n",
        "    Precission = TP/(TP+FP)\n",
        "    F1 = 2*((Precission*Recall)/(Precission+Recall))\n",
        "    return round(F1, 2)\n",
        "    raise NotImplementedError()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "409382277e058dd310f9a7aa4542e79a",
          "grade": true,
          "grade_id": "my_pairedttest_test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "onPvQ1RePsJY"
      },
      "outputs": [],
      "source": [
        "# Check you solution by running this cell\n",
        "# Case 1 data\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 1]\n",
        "y_pred = [1, 1, 0, 1, 0, 0, 1, 1]\n",
        "assert calculate_f1_score(y_true, y_pred) == 0.6\n",
        "\n",
        "\n",
        "# # Case 2 data\n",
        "y_true = [1, 0, 1, 1, 0, 1, 0, 1, 0, 1]\n",
        "y_pred = [1, 1, 0, 1, 0, 0, 1, 1, 1, 1]\n",
        "\n",
        "assert calculate_f1_score(y_true, y_pred) == 0.62\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wB6IrxBIPsJY"
      },
      "source": [
        "---\n",
        "## Question 3:\n",
        "\n",
        "#### Shapiro-Wilk Test\n",
        "Tests whether a data sample has a Gaussian distribution.\n",
        "\n",
        "Assumptions\n",
        "\n",
        "* Observations in each sample are independent and identically distributed (iid).\n",
        "\n",
        "Interpretation\n",
        "\n",
        "* H0: the sample has a Gaussian distribution.\n",
        "* H1: the sample does not have a Gaussian distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "46e413b53628a4d7763ce8b467327a5c",
          "grade": false,
          "grade_id": "my_normalityttest_ans",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q9-qqpC8PsJY",
        "outputId": "298c84d3-5fe7-49c5-c5a5-e52c43c30f0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1934097558259964"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from scipy.stats import shapiro\n",
        "data = [0.873, 2.817, 0.121, -0.945, -0.055, -1.436, 0.360, -1.478, -1.637, -1.869]\n",
        "\n",
        "def my_normalityttest(data):\n",
        "    \"\"\"Write code to to check the normality of the data. In other words,\n",
        "    you are checking if the data is normally distributed and return p value.\n",
        "    Hint: Please see what is shapiro test and how you can use it\n",
        "    https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.shapiro.html\"\"\"\n",
        "    # YOUR CODE HERE\n",
        "    stat,p = shapiro(data)\n",
        "    return p\n",
        "    raise NotImplementedError()\n",
        "\n",
        "my_normalityttest(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "ddf4ce4217df5678cc4c38ffb9623a47",
          "grade": true,
          "grade_id": "my_normalityttest_test",
          "locked": true,
          "points": 2,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VpiLJ10FPsJY"
      },
      "outputs": [],
      "source": [
        "# Check you solution by running this cell\n",
        "import math\n",
        "assert math.isclose(my_normalityttest(data), 0.193, rel_tol = 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1tWO7tsPsJY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}